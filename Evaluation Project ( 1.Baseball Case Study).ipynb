{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2871f02",
   "metadata": {},
   "source": [
    "__Eithar Elfatih Burie Abdelrahman DS2403__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37101050",
   "metadata": {},
   "source": [
    "# Baseball Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdbe80f",
   "metadata": {},
   "source": [
    "# __1.i Problem Identification__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda48bc1",
   "metadata": {},
   "source": [
    "__Project Description__\n",
    "\n",
    "    This dataset utilizes data from 2014 Major League Baseball seasons in order to develop an algorithm that predicts the number of wins for a given team in the 2015 season based on several different indicators of success. There are 16 different features that will be used as the inputs to the machine learning and the output will be a value that represents the number of wins. \n",
    "\n",
    "__Input features__\n",
    "\n",
    "    1.\tW - This indicates the number of Wins credited to a pitcher: number of games where pitcher was pitching while their team took the lead and went on to win, also the starter needs to pitch at least 5 innings of work.\n",
    "    \n",
    "    2.\tR - This indicates Runs scored. A run is scored when a player advances around first, second and third base and returns safely to home plate, touching the bases in that order, before three outs are recorded and all obligations to reach base safely on batted balls are met or assured: number of times a player crosses home plate.\n",
    "    \n",
    "    3.\tAB - This means At bat or time at bat. It's is a batter's turn batting against a pitcher: plate appearances, not including bases on balls, being hit by pitch, sacrifices, interference, or obstruction.\n",
    "    \n",
    "    4.\tH - This means Hit. It's also called a \"base hit\", is credited to a batter when the batter safely reaches or passes first base after hitting the ball into fair territory, without the benefit of either an error or a fielder's choice: reaching base because of a batted, fair ball without error by the defense.\n",
    "    \n",
    "    5.\t2B - This means the act of a batter striking the pitched ball and safely reaching second base without being called out by the umpire, without the benefit of a fielder's misplay (see error) or another runner being put out on a fielder's choice. A double is a type of hit (the others being the single, triple and home run) and is sometimes called a \"two-bagger\" or \"two-base hit\": hits on which the batter reaches second base safely without the contribution of a fielding error.\n",
    "    \n",
    "    6.\t3B - This measns a Triple.It's is the act of a batter safely reaching third base after hitting the ball, with neither the benefit of a fielder's misplay nor another runner being put out on a fielder's choice. A triple is sometimes called a \"three-bagger\" or \"three-base hit\": hits on which the batter reaches third base safely without the contribution of a fielding error.\n",
    "    7.\tHR - This means Home runs. It's scored when the ball is hit in such a way that the batter is able to circle the bases and reach home plate safely in one play without any errors being committed by the defensive team. A home run is usually achieved by hitting the ball over the outfield fence between the foul poles (or hitting either foul pole) without the ball touching the field: hits on which the batter successfully touched all four bases, without the contribution of a fielding error.\n",
    "    \n",
    "    8.\tBB - This means Base on balls (also called a \"walk\"). It occurs in baseball when a batter receives four pitches that the umpire calls balls, and is in turn awarded first base without the possibility of being called out: hitter not swinging at four pitches called out of the strike zone and awarded first base.\n",
    "    \n",
    "    9.\tSO - Also denoted as \"K\" means Strikeout. It occurs when a batter accumulates three strikes during a time at bat. It usually means that the batter is out: number of batters who received strike three.\n",
    "    10.\tSB - This means Stolen base. It occurs when a runner advances to a base to which they are not entitled and the official scorer rules that the advance should be credited to the action of the runner: number of bases advanced by the runner while the ball is in the possession of the defense.\n",
    "    \n",
    "    11.\tRA - This means Run Average. It refer to measures of the rate at which runs are allowed or scored.\n",
    "    \n",
    "    12.\tER - This means Earned run. It refers to any run that was fully enabled by the offensive team's production in the face of competent play from the defensive team: number of runs that did not occur as a result of errors or passed balls.\n",
    "    \n",
    "    13.\tERA - This means Earned Run Average. It refers to the average of earned runs allowed by a pitcher per nine innings pitched (i.e. the traditional length of a game). It is determined by dividing the number of earned runs allowed by the number of innings pitched and multiplying by nine: total number of earned runs (see \"ER\" above), multiplied by 9, divided by innings pitched.\n",
    "    \n",
    "    14.\tCG - This means Complete Game. It's the act of a pitcher pitching an entire game without the benefit of a relief pitcher. A pitcher who meets this criterion will be credited with a complete game regardless of the number of innings played: number of games where player was the only pitcher for their team.\n",
    "    \n",
    "    15.\tSHO - This means Shutout. It refers to the act by which a single pitcher pitches a complete game and does not allow the opposing team to score a run: number of complete games pitched with no runs allowed.\n",
    "    \n",
    "    16.\tSV - This means Save. It's credited to a pitcher who finishes a game for the winning team under certain prescribed circumstances: number of games where the pitcher enters a game led by the pitcher's team, finishes the game without surrendering the lead, is not the winning pitcher, and either (a) the lead was three runs or fewer when the pitcher entered the game; (b) the potential tying run was on base, at bat, or on deck; or (c) the pitcher pitched three or more innings.\n",
    "    \n",
    "    17.\tE - This means Errors. It's an act, in the judgment of the official scorer, of a fielder misplaying a ball in a manner that allows a batter or baserunner to advance one or more bases or allows a plate appearance to continue after the batter should have been put out. The term error is sometimes used to refer to the play during which an error was committed: number of times a fielder fails to make a play he should have made with common effort, and the offense benefits as a result.\n",
    "\n",
    "__Output: Number of predicted wins (W)__\n",
    "    \n",
    "    To understand the columns meaning, follow the link given below to understand the baseball statistics:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Baseball_statistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed696bca",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "__________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07f6329",
   "metadata": {},
   "source": [
    "# 1.ii Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c5e410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import sklearn\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.svm import SVR \n",
    "from scipy.stats import skew, stats, boxcox,yeojohnson\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split, LeaveOneOut, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression,Lasso, Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5b89664",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#read dataset\u001b[39;00m\n\u001b[0;32m      2\u001b[0m URL\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/FlipRoboTechnologies/ML_-Datasets/main/Baseball/baseball.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m baseball_\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(URL)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:713\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    710\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[0;32m    712\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[1;32m--> 713\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m _get_filepath_or_buffer(\n\u001b[0;32m    714\u001b[0m     path_or_buf,\n\u001b[0;32m    715\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m    716\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m    717\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m    718\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    719\u001b[0m )\n\u001b[0;32m    721\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[0;32m    722\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:363\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[0;32m    362\u001b[0m req_info \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[38;5;241m=\u001b[39mstorage_options)\n\u001b[1;32m--> 363\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m urlopen(req_info) \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[0;32m    364\u001b[0m     content_encoding \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    366\u001b[0m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:265\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;124;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;124;03mthe stdlib.\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m opener\u001b[38;5;241m.\u001b[39mopen(url, data, timeout)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[0;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m meth(req, response)\n\u001b[0;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[1;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39merror(\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m'\u001b[39m, request, response, code, msg, hdrs)\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[0;32m    562\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[1;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_chain(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "#read dataset\n",
    "URL=r'https://raw.githubusercontent.com/FlipRoboTechnologies/ML_-Datasets/main/Baseball/baseball.csv'\n",
    "baseball_=pd.read_csv(URL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a6781d",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91f0695",
   "metadata": {},
   "source": [
    "# 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df125197",
   "metadata": {},
   "source": [
    "__2.i Head / Tail__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e272646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe of csv\n",
    "df=pd.DataFrame(baseball_)\n",
    "df.index=df.index+1\n",
    "\n",
    "#show dataset head \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c01630",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show dataset tail\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1438b6",
   "metadata": {},
   "source": [
    "To make more sense of the features, using the given website i will change the column headers to more appropriate titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b301835a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename headers for more clarification from https://en.wikipedia.org/wiki/Baseball_statistics \n",
    "df.rename(columns={'W' : 'Wins','R' : 'Runs Scored', 'AB' : 'At Bat', 'H' : 'Hits', '2B' : 'Doubles', '3B' : 'Triples',\n",
    "                  'HR' : 'Home Runs', 'BB' : 'Base on Balls', 'SO' : 'Strike Outs', 'SB' : 'Stolen Base',\n",
    "                  'RA' : 'Runs Average', 'ER' : 'Earned Runs', 'ERA' : 'Earned Run Average', 'CG' : 'Complete Game',\n",
    "                 'SHO' : 'Shut Outs', 'SV' : 'Saves', 'E' : 'Errors'}, inplace=True)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b1741b",
   "metadata": {},
   "source": [
    "__2.ii Data Structure__\n",
    "\n",
    "2.ii.i Size, Shape and Columns  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075abfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show size/shapecolumns of our dataset.\n",
    "print('The dataset has a size of:',df.size)\n",
    "print('The dataset has a shape:',df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b81fa4",
   "metadata": {},
   "source": [
    "- The data set has 30 rows and 17 columns.\n",
    "- It contains 16 dependent features (input) that are statistic summaries (mentioned in 1.i), and 1 feature that is the dependent variable 'Win' (output). \n",
    "- This will be used to predict the number of wins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b326c4",
   "metadata": {},
   "source": [
    "2.ii.ii DataType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a727b89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show data types\n",
    "print('The data type of each column is as follows:\\n',df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653b8779",
   "metadata": {},
   "source": [
    "- All data types are int64 except 'Earned Runs Average' which is float 64. I will change all cloumns to float to have a unified set. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59470533",
   "metadata": {},
   "source": [
    "2.ii.iii Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2623c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show information about the dataframe \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a48e2a",
   "metadata": {},
   "source": [
    "- As all features are numerical data, I do not need to split into numerical and categorical and therefore this project is a regression analysis.     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ee68da",
   "metadata": {},
   "source": [
    "# 2.iii Objective\n",
    "\n",
    "__The goal of this project is to create an algorithm that predicts the number of wins (W) for Major League Baseball teams in the 2015 season. The prediction will utilize various performance metrics from the 2014 season. By examining 16 different input features representing various aspects of team and player performance, the model will identify the key factors that impact the number of games a team wins and forecast future performance based on these indicators.__ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2234ca52",
   "metadata": {},
   "source": [
    "__________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3deb8c84",
   "metadata": {},
   "source": [
    "__2.iv Data Pre-processing__ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a181b7d7",
   "metadata": {},
   "source": [
    "2.iv.i Duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d6cc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#indentify amount of duplicates (if any)\n",
    "print('From this, we can see there are no duplicates in this data set.')\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f71f70",
   "metadata": {},
   "source": [
    "2.iii.i.ii Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e702fec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of missing values in data set \n",
    "print('From this, we can see there are no missing values in this data set. No need to impute data.')\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbfef41",
   "metadata": {},
   "source": [
    "2.iv.i Heatmap of nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7517543",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.isna())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a24d02",
   "metadata": {},
   "source": [
    "__2.v Summary of data reading__\n",
    "\n",
    "-Data set has 30 rows and 17 columns.\n",
    "-All columns are of type 'int 64' and one is ' float64'. All data is numerical.\n",
    "-There are no duplicates.\n",
    "-There are no null values.\n",
    "-'Wins' is our target variable. The 16 other variables are independent.\n",
    "\n",
    "__Action__\n",
    "\n",
    "-To make all datatypes the same, i will convert all to 'float'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde0afb0",
   "metadata": {},
   "source": [
    "2.v.i Unify data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5753bc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all dtypes to float\n",
    "df=df.astype(float)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db37fea",
   "metadata": {},
   "source": [
    "I will now continue to analysis the data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9da76f",
   "metadata": {},
   "source": [
    "__________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2307cf31",
   "metadata": {},
   "source": [
    "# __3.Data visualisation__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f5e2a3",
   "metadata": {},
   "source": [
    "__3.i Univariate Analysis__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3b5eb9",
   "metadata": {},
   "source": [
    "3.i.i Target variable "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d104c29c",
   "metadata": {},
   "source": [
    "3.i.i.ii- Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c75b13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Wins' histplot \n",
    "plt.figure(figsize=(4,3))\n",
    "sns.histplot(df['Wins'])\n",
    "plt.title('Wins')\n",
    "plt.xlabel('Wins')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3e47c1",
   "metadata": {},
   "source": [
    "3.i.i.iii KDE plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e832d98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Wins' count\n",
    "plt.figure(figsize=(4,3))\n",
    "sns.kdeplot(df['Wins'], color='red')\n",
    "plt.title('Wins')\n",
    "plt.xlabel('Wins')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e091926",
   "metadata": {},
   "source": [
    "- The target variable seems to have an almost normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e01238",
   "metadata": {},
   "source": [
    "__3.i.ii Dependant variables__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc210c3b",
   "metadata": {},
   "source": [
    "3.i.ii.i - Distplot (with KDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4547bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of all features\n",
    "\n",
    "d_vars=df.drop(columns='Wins')\n",
    "\n",
    "# plot distplots with kde\n",
    "plt.figure(figsize=(24, 12))\n",
    "\n",
    "for i, col in enumerate(d_vars.columns,1):\n",
    "    plt.subplot(,2,i)\n",
    "    sns.distplot(d_vars[col], kde=True, bins=20)\n",
    "    plt.title(f'Distribution with KDE {col}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3914eee2",
   "metadata": {},
   "source": [
    "    'R' - left skewness, seems to have ouliters\n",
    "    'AB'- slightly left skewed, doesnt seem to have outliers\n",
    "    'H' - right skewness is present, also seems not to have outliers \n",
    "    '2B'- slight left skewness present \n",
    "    '3B'- slight skew to the right \n",
    "    'HR' - slight skew to the right \n",
    "    'BB' - seems to have slight skewness to the right \n",
    "    'SO' - skewed slightly to the left \n",
    "    'SB' - seems to be skewed to the right  \n",
    "    'RA'-  slight right skewness \n",
    "    'ER'-  slight right skewness\n",
    "    'ERA' - slightly skewed to th right \n",
    "    'CG'- seems skewed to the right, seems to have ome outliers  \n",
    "    'SHO'- right skewness\n",
    "    'SV'- right skewness\n",
    "    'E'- right skewness\n",
    "    \n",
    "    - Also, as we can see in the x axis, the scale of measure varies significantly across each variable\n",
    "    \n",
    "__Action:__\n",
    "\n",
    "    - Remove outliers \n",
    "    - Scale data before model building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226cf1a3",
   "metadata": {},
   "source": [
    "__3.iii Bivariate Anaylsis__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ebbf4b",
   "metadata": {},
   "source": [
    "3.iii.i box plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12483f64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# box plots for dependent variables to visualise distribution and outliers\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "num_cols_len=\n",
    "\n",
    "for i, col in enumerate(d_vars.columns,1):\n",
    "    plt.subplot(6,3,i)\n",
    "    sns.boxplot(x=d_vars[col], color='green')\n",
    "    plt.title(f'Distribution of {col}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb48877b",
   "metadata": {},
   "source": [
    "- outliers are present in Runs, Earned run average, Shut outs, Saves and Errors\n",
    "- As we can now clearly see the ouliers, we can remove them\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76eba6a6",
   "metadata": {},
   "source": [
    "3.iii.ii - Violin plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc832b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot violinplots with kde\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "for i, col in enumerate(d_vars.columns,1):\n",
    "    plt.subplot(6,3,i)\n",
    "    sns.violinplot(y=d_vars[col],)\n",
    "    plt.title(f'Violin plot of {col}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2922a59e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc609276",
   "metadata": {},
   "source": [
    "3.iii.iii Scatter plots ('Win vs [col]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d51d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scatter plots to show \n",
    "plt.figure(figsize=(14,35))\n",
    "\n",
    "for i, col in enumerate(d_vars.columns,1):\n",
    "    plt.subplot(8,2,i)\n",
    "    sns.scatterplot(x='Wins', y=col, data=df, hue=f'{col}', cmap='Greens')\n",
    "    plt.title(f'\"Win\" vs {col}', fontsize=14)\n",
    "    \n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64e55da",
   "metadata": {},
   "source": [
    "- here outliers are more visible than in univariate analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7aefe0",
   "metadata": {},
   "source": [
    "    'R' - has a positive relationship with 'Win'\n",
    "    'AB'- slightly negative relationship with the target variable\n",
    "    'H' - slight postive relation to 'Win'\n",
    "    '2B'- a strong positive relationship\n",
    "    '3B'- a negative resltionship to 'Win' \n",
    "    'HR' - a positivle relationship\n",
    "    'BB' - a positive relationship \n",
    "    'SO' - a slightly positive relation ship to the target variable \n",
    "    'SB' - a slight negative relationship to the target \n",
    "    'RA'-  a strong negative relationship to the target variable\n",
    "    'ER'-  a strong negative relationship to the target variable\n",
    "    'ERA' -a strong negative relationship to the target variable\n",
    "    'CG'- a weak positive realationship to 'Win' \n",
    "    'SHO'- a positive relationship to the target\n",
    "    'SV'- a strong positive relation to the target variable \n",
    "    'E'-  a slight negative relationship to win \n",
    "    \n",
    "From the above reg plots we can see that there are several features that have a positive relationship to the target variable. \n",
    "\n",
    "action\n",
    "\n",
    "    -to further investigate these relationships, first we will look at a correlation heatmap\n",
    "    -next, we will look at the skewness of each to further determin reltionships and correct if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655d3e2f",
   "metadata": {},
   "source": [
    "3.iii.iv Regplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aa6010",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scatter plots to show \n",
    "plt.figure(figsize=(14,35))\n",
    "\n",
    "for i, col in enumerate(d_vars.columns,1):\n",
    "    plt.subplot(8,2,i)\n",
    "    sns.regplot(x='Wins', y=col, data=df)\n",
    "    plt.title(f'\"Win\" vs {col}', fontsize=14)\n",
    "    \n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039c795f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91fa8262",
   "metadata": {},
   "source": [
    "3.iii.v - Pair plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4dc660",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show pair plots \n",
    "sns.pairplot(df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c4606d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42e82921",
   "metadata": {},
   "source": [
    "__3.iii Multivariate Analysis__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c597dbc5",
   "metadata": {},
   "source": [
    "3.iii.i Statistical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4585fb8c",
   "metadata": {},
   "source": [
    "3.iii.i.i- Statistics Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c85ee7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show description summary \n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d40e0d4",
   "metadata": {},
   "source": [
    "- All features are confirmed to have 30 rows, therfore no missing values.\n",
    "- All data is positive in nature and has no negative or invalid values to correct.\n",
    "- All features have significantly different scales of measure. \n",
    "- There is right skewness apparent in some features as the mean is higher in value than the median in:\n",
    "    'At Bat', 'Hits' 'Home Runs', 'Complete Game', 'Saves' and 'Errors'  \n",
    "- There is left skewness in 'Runs', 'Doubles', 'Triples', 'Vase on Balls', 'Strike Outs', 'Runs Average', 'Earned Runs', 'Earned RunsAverage' and 'Shut Outs' \n",
    "- 'Stolen Base' is the only column with equal mean and median of 83.5\n",
    "\n",
    "__actions:__\n",
    "\n",
    "- Scale unification\n",
    "- Univariate analysis for visual aid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b82f56a",
   "metadata": {},
   "source": [
    "3.iii.i.ii Unique Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32535459",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401b22f1",
   "metadata": {},
   "source": [
    "- As we can see above, majority of the columns have a unique number range of 20-30, while 'Shut Outs' has only 12 and 'Complete Game' has only 9 respectively.  \n",
    "- These two features could be seen as categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3240ab9",
   "metadata": {},
   "source": [
    "3.iii.i.iii - Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444bd848",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr().T\n",
    "plt.figure(figsize=(15,15))\n",
    "sns.heatmap(df.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3d7073",
   "metadata": {},
   "source": [
    "3.iii.i.iv - Correlation to Target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac12bb3",
   "metadata": {},
   "source": [
    "- for better visualisation, I have created the heatmap of the correlations\n",
    "- Here we can see the relationships between the independent vairables to each other as well as to Wins\n",
    "\n",
    "From the above heat map we can see:\n",
    "\n",
    "        - a few features are highly correlated with each other (Runs Average, Earned Runs and  Earned Runs Average)\n",
    "        - the target has high negative correlated to Runs Average, Earned Runs and  Earned Runs Average equally all at 0.81\n",
    "        - the most correlated independent feature is Saves at 0.67.\n",
    "       \n",
    "actions\n",
    "\n",
    "    - as their is multicollinearity between three features, this must be adrressed\n",
    "    -investigate more to see if columns should be dropped or joined "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addb8c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of correlation to wins \n",
    "corr_matx=df.corr()\n",
    "wins_corr=corr_matx['Wins']\n",
    "\n",
    "wins_df=wins_corr.reset_index()\n",
    "wins_df.columns=['Feature', 'Correlation to Wins']\n",
    "\n",
    "wins_df=wins_df.sort_values(by='Correlation to Wins', ascending=False )\n",
    "wins_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dc7495",
   "metadata": {},
   "source": [
    "- as 'Runs Average' and 'Earned Runs Average' are almost perfectily correlated with 'Earned Runs, iwill drop 'Earned Run Average' and check the skewness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cf882e",
   "metadata": {},
   "source": [
    "3.iii.i.v Drop columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03329cac",
   "metadata": {},
   "source": [
    "__3.iv - Outlier Detection__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfb9c43",
   "metadata": {},
   "source": [
    "3.iv.i Outlier Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5600b0",
   "metadata": {},
   "source": [
    "3.iv.i.i - IQR Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac11a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate IQR\n",
    "Q1 = df.quantile(0.25)\n",
    "Q3 = df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Remove outliers\n",
    "outlier_mask = ~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "df_filtered = df[outlier_mask]\n",
    "\n",
    "print(f'Original DataFrame shape: {df.shape}')\n",
    "print(f'Filtered DataFrame shape: {df_filtered.shape}')\n",
    "print('Percentage of data loss', (df.shape[0]-df_filtered.shape[0])/df.shape[0]*100)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3d46ee9b",
   "metadata": {},
   "source": [
    "3.iv.i.ii - Z score Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e115cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate z-score \n",
    "\n",
    "z_scores= stats.zscore(df)\n",
    "\n",
    "df_zscore=np.abs(z_scores)\n",
    "\n",
    "#define threshold \n",
    "threshold =3\n",
    "\n",
    "#create df with no outliers \n",
    "df_n=df[(df_zscore < threshold).all(axis=1)]\n",
    "print('The new dataframe without outliers:', df_n.shape)\n",
    "print('Percentage of data loss', (df.shape[0]-df_n.shape[0])/df.shape[0]*100)\n",
    "df_n.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7535dd",
   "metadata": {},
   "source": [
    "3.v - Skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33db619",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create df of skeweness values \n",
    "df_skew=df_n.skew().sort_values(ascending=False).to_frame('Skew')\n",
    "df_skew\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28656322",
   "metadata": {},
   "source": [
    "- 'Complete Game', 'Errors', and 'Hits', 'Saves' and 'Shut Outs' all have skewness above 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1bce7d",
   "metadata": {},
   "source": [
    "3.v.ii Skew Transformation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b8d927",
   "metadata": {},
   "outputs": [],
   "source": [
    "#log transform skew\n",
    "df_n['Complete Game']=np.log1p(df_n['Complete Game'])\n",
    "df_n['Errors']=np.log1p(df_n['Errors'])\n",
    "df_n['Hits']=np.log1p(df_n['Hits'])\n",
    "df_n['Saves']=np.log1p(df_n['Saves'])\n",
    "df_n['Shut Outs']=np.sqrt(df_n['Shut Outs'])\n",
    "\n",
    "\n",
    "print(df_n[['Runs Scored', 'Errors', 'Hits', 'Saves', 'Shut Outs' ]].skew())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083cb06a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d559f033",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n.skew().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6154ed",
   "metadata": {},
   "source": [
    "- After square root transformation, the skewness is still high in Errors and Hits  \n",
    "\n",
    "- I will leave as is ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f084ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n.skew().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5889a39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n=df_n.drop(columns=['Errors', 'Hits'])\n",
    "df_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2283f53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_n.drop('Wins', axis=1)\n",
    "Y=df_n['Wins']\n",
    "\n",
    "print(f'Target dataframe dimension:,{X.shape}')\n",
    "print(f'Y dataframe dimension:,{Y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e674d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abb1e28",
   "metadata": {},
   "source": [
    "data cleansing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26ffd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3addd3",
   "metadata": {},
   "source": [
    "feature engineering-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448f5da0",
   "metadata": {},
   "source": [
    "__Feature Scaling__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d297e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#***************************\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_norm=pd.DataFrame(X_scaled, columns=X.columns)\n",
    "X_norm.head()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59000866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5bf3739",
   "metadata": {},
   "source": [
    "VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74943f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find VIR for each column \n",
    "X_norm=pd.DataFrame(X_norm)\n",
    "vif= pd.DataFrame()\n",
    "vif['Features']= X_norm.columns\n",
    "vif['VIF Factor']=[variance_inflation_factor(X_norm.values, i) for i in range (len(X_norm.columns))]\n",
    "\n",
    "vif.sort_values(by='VIF Factor', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d04a706",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm=X_norm.drop(columns=['Earned Runs', 'Runs Average'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a636d0f",
   "metadata": {},
   "source": [
    " features are mostly abivd 10. \n",
    " most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca20fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vif= pd.DataFrame()\n",
    "vif['Features']= X_norm.columns\n",
    "vif['VIF Factor']=[variance_inflation_factor(X_norm.values, i) for i in range (len(X_norm.columns))]\n",
    "\n",
    "vif.sort_values(by='VIF Factor', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd16f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_norm.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ad1b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_norm, Y, test_size = 0.3, random_state=42)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('Y_train shape:', Y_train.shape)\n",
    "print('Y_test shape:', Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b894023",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_R= LinearRegression()\n",
    "\n",
    "lin_reg_results=[]\n",
    "\n",
    "for i in range(1,1000):\n",
    "    X_train_split,X_test_split,Y_train_split,Y_test_split=train_test_split(X_norm, Y,test_size=0.3,random_state=i)\n",
    "    \n",
    "    L_R.fit(X_train_split, Y_train_split)\n",
    "    \n",
    "    #make predictions\n",
    "    Y_predict_train=L_R.predict(X_train_split)\n",
    "    Y_predict_test=L_R.predict(X_test_split)\n",
    "    \n",
    "    #evaluate models \n",
    "    train_score=r2_score(Y_train_split,Y_predict_train)\n",
    "    test_score=r2_score(Y_test_split,Y_predict_test)\n",
    "    \n",
    "    #\n",
    "    mse_train=mean_squared_error(Y_train_split, Y_predict_train)\n",
    "    mse_test=mean_squared_error(Y_test_split, Y_predict_test)\n",
    "    \n",
    "    #\n",
    "    rmse_train= np.sqrt(mse_train)\n",
    "    rmse_test=np.sqrt(mse_test)    \n",
    "     \n",
    "    #    \n",
    "    c_val_score=cross_val_score(L_R,X_train_split ,Y_train_split, cv=5, scoring='r2')\n",
    "    c_val_mean=c_val_score.mean()*100 #percentage\n",
    "    \n",
    "    \n",
    "    lin_reg_results.append({\n",
    "        'Random State': i,\n",
    "        'Train Accuracy': train_score *100,\n",
    "        'Test Accuracy': test_score*100,\n",
    "        'Train MSE:': mse_train,\n",
    "        'Test MSE:' :mse_test,\n",
    "        'Train RMSE:' :rmse_train,\n",
    "        'Test RMSE:': rmse_test,\n",
    "        'Cross Validation Scores:': c_val_mean\n",
    "          })\n",
    "train_test_df_lin_reg=pd.DataFrame(lin_reg_results)\n",
    "\n",
    "train_test_df_sort_lin_reg=train_test_df_lin_reg.sort_values('Test Accuracy', ascending=False)\n",
    "train_test_df_sort_lin_reg.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1dab7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
